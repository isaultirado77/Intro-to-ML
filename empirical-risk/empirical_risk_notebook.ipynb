{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Theory**\n",
    "\n",
    "### Empirical Risk Minimization (ERM)\n",
    "\n",
    "#### Empirical Risk vs. Expected Risk\n",
    "En el contexto de ML, el objetivo *es encontrar un modelo que minimice la pérdida en los datos de prueba* y no solo en los datos de entrenamiento. Para formalizar esta idea, se definen dos conceptos clave:\n",
    "\n",
    "- **Expected Risk (Riesgo Esperado):** Es la pérdida promedio que el modelo tendría sobre toda la distribución de datos. Se define como:\n",
    "  \n",
    "   $$R(f) = \\mathbb{E}[\\ell(y, f(x))] = \\int \\ell(y, f(x)) p(x, y) dx dy$$\n",
    "  \n",
    "  Como la distribución real de los datos  $p(x, y)$  no es conocida, no podemos calcular este riesgo directamente.\n",
    "\n",
    "- **Empirical Risk (Riesgo Empírico):** Es la estimación del riesgo esperado usando un conjunto finito de datos de entrenamiento $\\{(x_n, y_n)\\}_{n=1}^{N}$:\n",
    "  \n",
    "  $$R_{emp}(f) = \\frac{1}{N} \\sum_{n=1}^{N} \\ell(y_n, f(x_n))$$\n",
    "  \n",
    "  El **Empirical Risk Minimization (ERM)** consiste en minimizar este riesgo empírico para encontrar los parámetros óptimos del modelo.\n",
    "\n",
    "#### Necesidad de un Test Set\n",
    "Minimizar el riesgo empírico puede llevar a un modelo que se desempeña bien en los datos de entrenamiento pero no generaliza a nuevos datos. Para evaluar la capacidad del modelo de generalizar, se dividen los datos en:\n",
    "\n",
    "- **Training Set (Conjunto de Entrenamiento):** Se usa para ajustar los parámetros del modelo.\n",
    "- **Validation Set (Conjunto de Validación):** Se usa para ajustar hiperparámetros y evitar sobreajuste (*overfitting*).\n",
    "- **Test Set (Conjunto de Prueba):** Se usa solo al final para evaluar la generalización del modelo en datos no vistos.\n",
    "\n",
    "#### Regularización: Evitar el Sobreajuste\n",
    "Cuando un modelo es demasiado complejo, puede aprender no solo los patrones de los datos de entrenamiento, sino también el ruido. Para evitar este sobreajuste, se emplea **regularización**, que penaliza la complejidad del modelo.\n",
    "\n",
    "Algunas técnicas comunes son:\n",
    "\n",
    "- **Regularización L2 (Ridge Regression):** Agrega un término de penalización sobre la magnitud de los parámetros:\n",
    "  \n",
    "$$  R_{reg}(f) = \\frac{1}{N} \\sum_{n=1}^{N} \\ell(y_n, f(x_n)) + \\lambda \\|\\theta\\|^2 $$  \n",
    "  Donde $\\lambda$ controla la cantidad de regularización.\n",
    "\n",
    "- **Regularización L1 (Lasso Regression):** Similar a la regularización L2, pero en lugar de penalizar la norma cuadrática, penaliza la norma absoluta de los parámetros.\n",
    "\n",
    "#### Cross-Validation: Evaluación del Modelo\n",
    "La validación cruzada es una técnica utilizada para evaluar el rendimiento de un modelo sin desperdiciar datos en un único conjunto de validación.\n",
    "\n",
    "- **K-Fold Cross-Validation:**\n",
    "  - Se divide el conjunto de datos en $K$ partes.\n",
    "  - Se entrena el modelo $K$ veces, usando $K-1$ partes para entrenar y una para validar.\n",
    "  - Se promedian los resultados para obtener una mejor estimación del rendimiento del modelo.\n",
    "\n",
    "Esta técnica ayuda a seleccionar el mejor modelo e hiperparámetros sin riesgo de sobreajustar a un conjunto de validación específico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de emprical risk (usando MSE) vs expected risk\n",
    "#### MSE: Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_california_housing()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name='MedHouseVal')\n",
    "\n",
    "# Alternative form: \n",
    "# X, y = fetch_california_housing(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  \n",
       "0        -122.23  \n",
       "1        -122.22  \n",
       "2        -122.24  \n",
       "3        -122.25  \n",
       "4        -122.25  \n",
       "...          ...  \n",
       "20635    -121.09  \n",
       "20636    -121.21  \n",
       "20637    -121.22  \n",
       "20638    -121.32  \n",
       "20639    -121.24  \n",
       "\n",
       "[20640 rows x 8 columns]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20640.000000\n",
       "mean         2.068558\n",
       "std          1.153956\n",
       "min          0.149990\n",
       "25%          1.196000\n",
       "50%          1.797000\n",
       "75%          2.647250\n",
       "max          5.000010\n",
       "Name: MedHouseVal, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split and Baseline Model\n",
    "\n",
    "# 1. Dividimos en train y temporal datasets (proportion = [0.6, 0.4])\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y,\n",
    "                                                    test_size=0.4,  # temp_size = 0.4 -> train_size = 0.6\n",
    "                                                    random_state=42\n",
    "                                                    )\n",
    "\n",
    "# 2. Subdividimos temp en validation y test (proportion = 0.5)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 0.5326\n"
     ]
    }
   ],
   "source": [
    "#  Train a linear regression model\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "print(f\"Validation MSE: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial Regression and Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a polynomial feature\n",
    "\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_val_poly = poly.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 3 MSE: 13.7254\n"
     ]
    }
   ],
   "source": [
    "model_poly = LinearRegression()\n",
    "model_poly.fit(X_train_poly, y_train)\n",
    "y_pred_poly = model_poly.predict(X_val_poly)\n",
    "mse_poly = mean_squared_error(y_val, y_pred_poly)\n",
    "print(f\"Degree 3 MSE: {mse_poly:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (virt_imp)",
   "language": "python",
   "name": "virt_imp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
